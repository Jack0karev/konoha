{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jack0karev/konoha/blob/master/Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ro8Cz7d2LQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4t-D23l2NIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() # здесь нужно будет загрузить тот файл из каггл API token, главное, чтобы он назвался kaggle.json "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PgOX8MG2bo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json  ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9ROmxBv2-up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c iad-deep-learning-sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTWXVJY_EmOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip x_test.txt.zip  x_test.txt\n",
        "!unzip x_train.txt.zip  x_train.txt\n",
        "!unzip y_train.csv.zip  y_train.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwvqlTW9Gtoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "x_test = pd.read_csv(\"x_test.txt\", sep='\\r\\t',header=None)\n",
        "x_train = pd.read_csv(\"x_train.txt\", sep='\\r\\t',header=None)\n",
        "y_train = pd.read_csv(\"y_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjR5B73pjmEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ojMuIIHjmCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Oz1DP2qjmAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in tqdm(df[0]):\n",
        "\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "\n",
        "        words = word_tokenize(review_text.lower())\n",
        "\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUTPSLxkjl7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences = clean_sentences(x_train[:################]) # здесь ты задаешь число входных данных их всего там 3600000 советую взять 1000000\n",
        "test_sentences = clean_sentences(x_test)\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVLVNsjmjl4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in tqdm(train_sentences):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "\n",
        "print(len(list(unique_words)))\n",
        "print(len_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQBc6SXjl0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(train_sentences)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
        "\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "y = y_train.Probability.values\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7uHlHghjlx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
        "callback = [early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJucQYp2jlvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
        "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbXcBNL5jlqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(X_train, y[:#################], # здесь ты задаешь число входных данных их всего там 3600000 советую взять 1000000\n",
        "                  validation_split = 0.1,epochs=6,\n",
        "                  batch_size=256, verbose=1,\n",
        "                  callbacks=callback)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpwebmNsjlm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7PW7fVajkxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip random_prediction.csv.zip random_prediction.csv\n",
        "df = pd.DataFrame(data)\n",
        "df1 = pd.read_csv('random_prediction.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WZE_XtgjkuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "total = df1.Id\n",
        "total = pd.DataFrame(total)\n",
        "total['Probability'] = np.around(df[0], decimals=5).astype(np.double)\n",
        "total.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MPJIzAljkqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total.to_csv('sentiment1.csv', index = False)\n",
        "files.download('sentiment1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}